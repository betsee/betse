# --------------------( LICENSE                           )--------------------
# Copyright 2014-2019 by Alexis Pietak & Cecil Curry.
# See "LICENSE" for further details.
#
# --------------------( SYNOPSIS                          )--------------------
# Project-wide GitLab-CI configuration, integrating the in-house
# free-as-in-beer continuous integration (CI) service exposed by GitLab with
# this project's "py.test"-driven test suite. GitLab-specific terminology used
# by this service includes (from highest- to lowest-level):
#
# * GitLab-CI, GitLab's high-level CI service coordinating project-specific and
#   shared Runners with projects - including project artefacts and metadata.
# * Runner, a low-level virtual machine conforming to the GitLab Runner API and
#   acquiring builds to process through the GitLab-CI coordinator API. There
#   exist two categories of Runners:
#   * Project Runners, hosted either directly by project maintainers on private
#     servers *OR* indirectly by for-profit intermediaries on private servers
#     paid for by the project maintainers. As the nomenclature implies, Project
#     Runners are specific to and hence accessible by only the project to which
#     they are assigned. In either case, "paid" and "private" are the general
#     keywords here. (Inapplicable for our use case.)
#   * Shared Runners. As the nomenclature implies, Shared Runners are
#     accessible to all projects on a GitLab instance. Hence, all projects
#     hosted by the official gitlab.com host share access to the same Shared
#     Runners. Shared Runners are hosted either:
#     * If the GitLab instance hosting this project is *NOT* the official
#       gitlab.com, then by the prior mechanisms (e.g., by project maintainers
#       or for-profit intermediaries).
#     * If the GitLab instance hosting this project is the official gitlab.com,
#       then by the for-profit intermediary with whom gitlab.com has partnered:
#       as of this writing, DigitalOcean. In this and only this special
#       edge-case, Shared Runners are free-as-in-beer for both public and
#       private repositories hosted with this instance. An inevitable caveat,
#       of course, is that only Linux-based Shared Runners are available. To
#       quote the official response to a recent issue report requesting both OS
#       X and Windows support:
#       "If you are writing about shared runners on GitLab.com, then they are
#        only Linux based (with docker executor). If you need Windows, Mac or
#        any other OS for the runner, then you need to install it on your own
#        host and register it in your project on GitLab.com."
#
# This gitlab.com-hosted project has been configured to enable Linux-based
# Shared Runners. Exercising tests on either OS X or Windows requires doing so
# on an external third-party free-as-in-beer CI service specific to that
# platform and then integrating this service with GitLab.

# ....................{ DOCKER                            }....................
# For a list of all available Docker images, see the search bar at the top of
# "https://hub.docker.com". To find relevant images, consider (in order):
#
# * Either:
#   * Google "docker python3 matplotlib". Since Matplotlib transitively
#     requires most dependencies required by this project, this query
#     (typically) yields maximally relevant images.
#   * Search the Docker Hub Registry directly by:
#     * Switching the list box from its useless default of "All" to either
#       "Downloads" or "Stars", sorting hits on image usage or upvotes.
#     * Searching for "python". Unfortunately, since the search engine *ONLY*
#       searches image names rather than some combination of names,
#       descriptions, and/or Dockerfiles, the resulting hits tend to be only
#       minimally relevant.
# * For each image of interest, clicking the "Tags" subpage to list:
#   * All available tags for that image.
#   * For each such tag, the compressed filesize of that tagged image.
#
# All else being equal, the smallest image pre-packaging the largest number of
# dependencies required for our scientific stack is the most ideal. Note that
# downloading and installing dependencies via a package manager is
# significantly slower than merely downloading an image pre-packaging those
# dependencies.
#
# Docker official images are rumoured to be switching from an Ubuntu- to an
# Alpine Linux-based OS. Thanks to an obsessive-compulsive attention to
# minification, Alpine Linux is ideal for Docker-based CI. While Alpine Linux
# comes bundled with a package manager ("apk") providing a variety of
# scientific Python packages (e.g., "py-numpy"), these packages are all sadly
# built against the non-standard musl libc implementation optimized for Alpine
# Linux rather than the standard glibc libc implementation bundled with most
# Linux distributions. Technically, a glibc compatibility layer for musl named
# "gcompat" does exist but appears to be inapplicable to Python usage. In any
# case, musl is effectively incompatible with glibc and hence "manylinux"
# Python wheels -- which, by de facto industry standard, are linked against
# glibc rather than musl. So, Alpine Linux-based Docker images are entirely
# inappropriate for Python usage and *MUST* strictly be avoided. See also:
#     https://github.com/docker-library/docs/issues/904
#     https://pythonspeed.com/articles/base-image-python-docker-images
#
# Consensus in the open-source Python community strongly advises use of the
# official Python images published by Docker themselves in their so-called
# "slim" variants (e.g., "python:3.7-slim-buster"), which officially support
# *ALL* modern stable releases of Python. Moreover, these images are stable,
# well-maintained, and minified almost as extremely as Alpine Linux Docker
# images but with *NONE* of the disadvantages of the latter. See also:
#
# * Docker Hub Registery entry for this image:
#   https://hub.docker.com/_/python
# * Docker Hub Registery entry for the low-level image this image is based on:
#   https://hub.docker.com/_/buildpack-deps
# * Open-source GitHub repository hosting this image's Dockerfile:
#   https://github.com/ContinuumIO/docker-images/tree/master/anaconda3
# * Platform-specific lists of all Anaconda packages installed by default:
#   http://repo.continuum.io/pkgs

# Colon-delimited name and tag of the Docker image registered at the Docker Hub
# Registery (e.g., "python:3", denoting the Docker image named "python" tagged
# as "3"), provisioning the Python stack to be tested against.
#
# A name is an alphanumeric label such that:
#
# * For third-party Docker images, the name is prefixed by an organization name
#   delimited by a "/" character (e.g., "continuumio/anaconda3").
# * For official Docker images published by Docker itself, the name is a bare
#   label prefixed by *NO* such delimiter (e.g., "python").
#
# A tag is an alphanumeric label unique to an image, whose name is itself an
# alphanumeric label unique across all images registered at the Docker Hub
# Registery. A tag typically specifies the version of that image to be used.
#
# Lastly, note that the test matrix defined below explicitly overrides this
# basic image for every test environment. This is only a desperate fallback.
image: python

# ....................{ GLOBALS ~ env                     }....................
# Dictionary mapping from the name to value of each environment variable to be
# "globally" exported and hence accessible to *ALL* commands run below.
variables:
  # ...................{ GLOBALS ~ public                  }...................
  # Public environment variables specific to third-party applications.
  #
  # Note that *ALL* pathnames to be cached below should be prefixed by
  # "${CI_PROJECT_DIR}/", the absolute dirname of the pipeline-specific
  # directory containing this project. See the "WARNING" below for details.

  # Reduce the Advanced Package Tool (APT) package manager provided by this
  # Debian Linux-based image to headless behaviour. To quote "man debconf":
  #     "This is the anti-frontend. It never interacts with you at all, and
  #      makes the default answers be used for all questions. It might mail
  #      error messages to root, but that's it; otherwise it is completely
  #      silent and unobtrusive, a perfect frontend for automatic installs. If
  #      you are using this front-end, and require non-default answers to
  #      questions, you will need to preseed the debconf database; see the
  #      section below on Unattended Package Installation for more details."
  # Note that the "apt --yes" option technically obsoletes this setting for
  # most purposes, but that a little explicitness never hurt no one never.
  DEBIAN_FRONTEND: noninteractive

  # Instruct Matplotlib to cache metadata to the build-relative directory
  # repeated in the "cache:" section below.
  MPLCONFIGDIR: "${CI_PROJECT_DIR}/.mpl-cache"

  # Instruct X11-specific utilities to do so as well.
  XDG_CACHE_HOME: "${CI_PROJECT_DIR}/.cache/"

  # ...................{ GLOBALS ~ private                 }...................
  # Private environment variables specific to this configuration. To avoid
  # conflict with third-party applications, the name of each such variable is
  # intentionally prefixed by "_".

# ....................{ GLOBALS ~ cache                   }....................
cache:
  # Cache all subdirectories and files of the build directory *NOT* already
  # tracked by Git for this repository, in addition to those paths explicitly
  # cached below. In theory, all paths requiring caching should be explicitly
  # cached below; in practice, this fallback ensures that paths omitted below
  # will still be implicitly cached.
  # untracked: true

  # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
  # WARNING: Due to an outstanding issue, GitLab-CI currently ignores *ALL*
  # cache paths outside the build directory. See also:
  #     https://gitlab.com/gitlab-org/gitlab-ce/issues/4431
  # Sadly, this implies that cache paths listed below *MUST* be both relative
  # to and contained in the build directory. Ensure that each such path is
  # prefixed by neither "/", "./", or "../" *NOR* by any variable expanding to
  # such a path (e.g., "$HOME").
  # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
  #
  # List of the relative or absolute dirnames of all directories to be
  # preserved between CI pipelines. (Note that relative dirnames are relative
  # to the current build directory.)
  paths:
    # Directory to which Matplotlib caches metadata (e.g., on fonts).
    - .mpl-cache/

    # Directory to which X11-specific utilities metadata (e.g., on fonts).
    - .cache/

# ....................{ STAGES                            }....................
# List of all stages to be run by this pipeline (in order).
#
# In Gitlab-CI parlance, a "stage" is an abstract tag to which a "job" (defined
# below) is assigned. Each job is *ALWAYS* tagged with exactly one stage,
# defaulting to the "test" stage. All jobs tagged with the same stage are run
# in parallel *BEFORE* all jobs tagged with the next stage in this list are run
# in parallel. If any job fails, the entire stage to which that job belongs
# fails. If any stage fails, the entire pipeline fails; else, the pipeline
# succeeds.
#
# Previously, this pipeline listed the following two stages:
#
#     stages:
#       - build
#       - test
#
# These stages were implemented by the following two jobs:
#
# * "betse_build", implementing the "build" stage by installing dependencies.
# * "betse_test", implementing the "test" stage by testing this application.
#
# Sadly, this seemingly reasonable partition of the pipeline workflow silently
# ceased working at some unidentifiable time in the development history. To
# remedy this, all work previously previously performed by the "betse_build"
# job is now performed as a global "before_script" key. While non-ideal, there
# appears to be no remedy as yet.
stages:
  # - build
  - test

# ....................{ JOBS                              }....................
# In Gitlab-CI parlance, a "job" is a container of all Gitlab-CI configuration
# metadata guaranteed to be enabled for the same duration of the pipeline time.
# This contradicts conventional *nix-oriented parlance, in which a "job" is
# simply a subprocess owned by a parent shell process.
#
# Each Gitlab-CI job is uniquely identified by a top-level user-defined key of
# this YAML file *NOT* already reserved for use as a top-level official key by
# the ".gitlab-ci.yml" file format (e.g., "artifact", "cache", "script"). A job
# may have any arbitrary non-reserved name and may contain any top-level
# official key, thus confining the action of that key (e.g., artifact building,
# caching, script commands) to that job.

# ....................{ JOBS ~ test : common              }....................
# Mapping-style anchor to be interpolated into each job's mapping below.
.test_common: &test_common
  # Stage to run this job under. Note that "test" is technically the default
  # stage and hence need *NOT* be explicitly specified here. For disambiguity,
  # we do so anyway.
  stage: test

  # List of all external commands run *BEFORE* running those listed by the
  # "script" key of any job below. These commands build and install both this
  # application and all third-party dependencies required by this application.
  before_script:
    # Update all system-wide packages installed by default with this image for
    # the temporary duration of this job and, if a package cache has yet to be
    # created, do so.
    #
    # This command *MUST* be run before attempting to install any dependencies
    # via the system-wide package manager, as the latter requires the package
    # cache created by the former. If omitted, the first such attempt fails
    # with a fatal error resembling:
    #
    #    $ apt-get install -y graphviz
    #    Reading package lists...
    #    Building dependency tree...
    #    Reading state information...
    #    E: Unable to locate package graphviz
    - apt-get update --quiet --yes

    # Install all dependencies available via the system-wide package manager.
    # Doing so is typically both faster and stabler than doing so via "pip"
    # and, in any case, supports installation of non-Pythonic dependencies
    # unavailable via "pip" (e.g., "graphviz").
    - apt-get install --quiet --yes graphviz

    # Install all preliminary Python dependencies with "pip". Note that the
    # "tox.ini" file provided by this project installs:
    #
    # * All remaining Python dependencies (e.g., "pytest", "numpy", "scipy").
    # * This project itself (e.g., "betse").
    - python3 -m pip --quiet install tox

# ....................{ JOBS ~ test : version             }....................
# Note that non-slim Docker Python images are currently preferred to slim
# variants with names suffixed by "-slim" (e.g., "python:3.8-slim"), as the
# latter fail to include C and C++ compilers required to build and install
# wheels for Python packages both lacking official wheels *AND* containing
# mandatory C extensions (e.g., "psutil"). Installing compilers under slim
# variants would circumvent this but also defeat the purpose of doing so.

# Python 3.5-specific test job, exercising this project's full test suite.
test_python35:
  <<: *test_common
  image: python:3.5
  script: python3 -m tox -e py35

# Python 3.6-specific test job, exercising this project's full test suite.
test_python36:
  <<: *test_common
  image: python:3.6
  script: python3 -m tox -e py36

# Python 3.7-specific test job, exercising this project's full test suite.
test_python37:
  <<: *test_common
  image: python:3.7
  script: python3 -m tox -e py37

# Python 3.8-specific test job, exercising this project's full test suite.
test_python38:
  <<: *test_common
  image: python:3.8
  script: python3 -m tox -e py38
